<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>fehu - Reinforcement learning for OCaml | raven</title>
  <link rel="stylesheet" href="/styles.css">
</head>
<body>
  <main class="main-content">
    <nav class="fehu-nav nav-breadcrumb">
      <a href="/">raven</a> / fehu <span class="color-teal rune-symbol">ᚠ</span>
      [ <a href="/docs/fehu/">docs</a> |
      <a href="https://github.com/raven-ml/raven/tree/main/fehu">source</a> ]
    </nav>

    <div class="fehu-hero hero">
      <h1>fehu <span style="font-size: 48px; margin-left: -20px; opacity: 0.6;" class="color-teal">ᚠ</span></h1>
      <p class="tagline">Gymnasium's ease. Stable Baselines' algorithms. OCaml's type safety.</p>
    </div>

    <hr>

    <h2>why fehu?</h2>

    <div class="feature-grid">
      <div>
        <h3 class="color-teal">type-safe environments</h3>
        <p>Environment APIs catch shape mismatches at compile time. Never debug observation space errors at runtime.</p>
      </div>
      <div>
        <h3 class="color-teal">functional RL</h3>
        <p>Agents are immutable. Experience replay is just data. Everything composes naturally.</p>
      </div>
      <div>
        <h3 class="color-teal">built on rune</h3>
        <p>Policy gradients and Q-learning with automatic differentiation. Neural networks from Kaun.</p>
      </div>
      <div>
        <h3 class="color-teal">standard benchmarks</h3>
        <p>CartPole, MountainCar, and more. Compare directly with Gymnasium and Stable Baselines3.</p>
      </div>
    </div>

    <hr>

    <h2>show me the code</h2>

    <div class="code-compare">
      <div>
        <h4>Python (Gymnasium)</h4>
        <pre class="language-python"><code class="language-python">import gymnasium as gym

# Create environment
env = gym.make('CartPole-v1')
obs, info = env.reset()

# Run episode
done = False
while not done:
    action = env.action_space.sample()
    obs, reward, term, trunc, info = \
        env.step(action)
    done = term or trunc</code></pre>
      </div>
      <div>
        <h4>FEHU</h4>
        <pre class="language-ocaml"><code class="language-ocaml">open Fehu

(* Create environment *)
let rng = Rune.Rng.key 42 in
let env = Fehu_envs.Cartpole.make ~rng ()

(* Run episode *)
let obs, _info = Env.reset env () in
let done_ = ref false in
while not !done_ do
  let action = Space.sample (Env.action_space env) in
  let t = Env.step env action in
  done_ := t.terminated || t.truncated
done</code></pre>
      </div>
    </div>

    <hr>

    <h2>train an agent</h2>

    <pre class="language-ocaml"><code class="language-ocaml">open Fehu
open Kaun

(* Create policy network *)
let policy = Layer.sequential [
  Layer.linear ~in_features:4 ~out_features:128 ();
  Layer.relu ();
  Layer.linear ~in_features:128 ~out_features:2 ();
]

(* Train with REINFORCE *)
let agent = Fehu_algorithms.Reinforce.create
  ~policy_network:policy
  ~n_actions:2
  ~rng
  { learning_rate = 0.001; gamma = 0.99; ... }

let agent = Fehu_algorithms.Reinforce.learn
  agent ~env ~total_timesteps:100_000
  ~callback:(fun ~iteration ~metrics ->
    Printf.printf "Episode %d: Return = %.2f\n"
      iteration metrics.episode_return; true)
  ()</code></pre>

    <hr>

    <h2>what's implemented</h2>

    <p>Fehu is in active development. Here's what works today:</p>

    <div class="feature-grid">
      <div>
        <h3 class="color-teal">environments</h3>
        <ul style="list-style: none; padding: 0;">
          <li>✓ CartPole-v1</li>
          <li>✓ MountainCar-v0</li>
          <li>✓ GridWorld (custom)</li>
          <li>✓ RandomWalk (custom)</li>
        </ul>
      </div>
      <div>
        <h3 class="color-teal">algorithms</h3>
        <ul style="list-style: none; padding: 0;">
          <li>✓ REINFORCE (policy gradient)</li>
          <li>✓ DQN (deep Q-network)</li>
          <li>✓ Experience replay buffers</li>
          <li>⏳ PPO, A2C (coming soon)</li>
        </ul>
      </div>
    </div>

    <hr>

    <h2>design principles</h2>

    <p><b>Type-safe environments.</b> Observation and action spaces are strongly typed. The compiler catches dimension mismatches before you run your training loop.</p>

    <p><b>Functional agents.</b> Agents are immutable values. Policy updates return new agents. Experience replay is just an array of transitions.</p>

    <p><b>Leverage the Raven ecosystem.</b> Use Kaun for neural networks, Rune for autodiff, and Nx for tensor operations. Fehu is thin glue code over powerful primitives.</p>

    <hr>

    <h2>get started</h2>

    <p>Fehu isn't released yet. For now, check out the <a href="/docs/fehu/">documentation</a> to learn more.</p>

    <p>When it's ready:</p>

    <pre class="language-bash"><code class="language-bash">opam install fehu</code></pre>

    <pre class="language-ocaml"><code class="language-ocaml">open Fehu

let rng = Rune.Rng.key 42 in
let env = Fehu_envs.Cartpole.make ~rng ()

(* Create and train your agent *)
let agent = train_cartpole env ~episodes:500</code></pre>
  </main>

</body>
</html>