<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>saga - Text tokenization for OCaml | raven</title>
  <link rel="stylesheet" href="/styles.css">
</head>
<body>
  <main class="main-content">
    <nav class="saga-nav nav-breadcrumb">
      <a href="/">raven</a> / saga
      [ <a href="/docs/saga/">docs</a> |
      <a href="https://github.com/raven-ml/raven/tree/main/saga">source</a> ]
    </nav>

    <div class="saga-hero hero">
      <h1>saga</h1>
      <p class="tagline">Hugging Face quality. OCaml efficiency. Production-ready tokenization.</p>
    </div>

    <hr>

    <h2>why saga?</h2>

    <div class="feature-grid">
      <div>
        <h3 class="color-teal">modern tokenizers</h3>
        <p>BPE and WordPiece out of the box. Compatible with pretrained models from Hugging Face.</p>
      </div>
      <div>
        <h3 class="color-teal">unicode done right</h3>
        <p>Proper handling of multilingual text, emoji, and special characters. No surprises.</p>
      </div>
      <div>
        <h3 class="color-teal">direct tensor encoding</h3>
        <p>Encode straight to Nx tensors. Batch processing with padding and truncation built in.</p>
      </div>
      <div>
        <h3 class="color-teal">type-safe vocabularies</h3>
        <p>Vocabularies that can't go out of sync. Special tokens that always exist.</p>
      </div>
    </div>

    <hr>

    <h2>show me the code</h2>

    <div class="code-compare">
      <div>
        <h4>PYTHON</h4>
        <pre class="language-python"><code class="language-python">from transformers import AutoTokenizer

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    "bert-base"
)

# Tokenize
tokens = tokenizer.tokenize("Hello world")

# Encode to IDs
input_ids = tokenizer.encode(
    "Hello world",
    max_length=128,
    padding="max_length"
)

# Batch encode
batch = tokenizer(
    ["Hello", "World"],
    padding=True,
    return_tensors="pt"
)</code></pre>
      </div>
      <div>
        <h4>SAGA</h4>
        <pre class="language-ocaml"><code class="language-ocaml">open Saga

(* Load tokenizer *)
let tokenizer = 
  Wordpiece.from_files 
    ~vocab:"vocab.txt"

(* Tokenize *)
let tokens = Wordpiece.tokenize tokenizer "Hello world"

(* Encode to IDs *)
let input_ids = 
  encode ~vocab 
    ~max_len:128 
    "Hello world"

(* Batch encode - returns Nx tensor *)
let batch = 
  encode_batch ~vocab
    ~pad:true
    ["Hello"; "World"]</code></pre>
      </div>
    </div>

    <hr>

    <h2>tokenization that works</h2>

    <pre class="language-ocaml"><code class="language-ocaml">(* Simple tokenization *)
let tokens = tokenize "Hello world! 你好世界"
(* ["Hello"; "world"; "!"; "你好世界"] *)

(* Build vocabulary from corpus *)
let vocab = 
  vocab ~max_size:30000 ~min_freq:2
    (List.concat_map tokenize corpus)

(* BPE tokenization *)
let bpe = Bpe.from_files ~vocab:"vocab.json" ~merges:"merges.txt" in
let tokens = Bpe.tokenize bpe "unrecognizable"
(* ["un", "##rec", "##ogn", "##iz", "##able"] *)

(* Unicode normalization *)
let clean = 
  normalize ~lowercase:true ~strip_accents:true 
    "Café RÉSUMÉ"
(* "cafe resume" *)</code></pre>

    <hr>

    <h2>the good parts</h2>

    <p><b>Pretrained compatibility</b><br>
    Load vocabularies from Hugging Face models. Your BERT tokenizer works out of the box.</p>

    <p><b>Batch processing that scales</b><br>
    Encode thousands of texts efficiently. Automatic padding and truncation. Direct tensor output.</p>

    <p><b>Unicode that doesn't break</b><br>
    Proper grapheme clustering. CJK text handled correctly. Emoji that don't corrupt your tokens.</p>

    <p><b>Type safety throughout</b><br>
    Vocabularies that can't get out of sync. Special tokens that are always defined. No string keys to typo.</p>

    <hr>

    <h2>what's implemented</h2>

    <div class="feature-grid">
      <div>
        <h3 class="color-teal">tokenizers</h3>
        <ul>
          <li>✓ Word-level</li>
          <li>✓ Character-level</li>
          <li>✓ BPE</li>
          <li>✓ WordPiece</li>
          <li>○ SentencePiece</li>
        </ul>
      </div>
      <div>
        <h3 class="color-teal">preprocessing</h3>
        <ul>
          <li>✓ Unicode normalization</li>
          <li>✓ Accent stripping</li>
          <li>✓ Case folding</li>
          <li>✓ Whitespace cleanup</li>
          <li>✓ Control char removal</li>
        </ul>
      </div>
      <div>
        <h3 class="color-teal">features</h3>
        <ul>
          <li>✓ Vocabulary management</li>
          <li>✓ Special tokens</li>
          <li>✓ Batch encoding</li>
          <li>✓ Padding/truncation</li>
          <li>○ Training tokenizers</li>
        </ul>
      </div>
      <div>
        <h3 class="color-teal">integration</h3>
        <ul>
          <li>✓ Nx tensor output</li>
          <li>✓ File I/O</li>
          <li>✓ Token caching</li>
          <li>○ Rust backend</li>
          <li>○ Model zoo</li>
        </ul>
      </div>
    </div>

    <hr>

    <h2>get started</h2>

    <p>Saga is part of the Raven ecosystem. When it's released:</p>

    <pre class="language-bash"><code class="language-bash">opam install saga</code></pre>

    <pre class="language-ocaml"><code class="language-ocaml">open Saga

let () =
  let text = "Hello world! How are you?" in
  let tokens = tokenize text in
  List.iter print_endline tokens</code></pre>

    <p>For now, check out the <a href="/docs/saga/">documentation</a> to learn more.</p>
  </main>

</body>
</html>