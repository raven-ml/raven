# MLP

Train a multi-layer perceptron from scratch using Rune's automatic differentiation. Computes MSE loss, derives gradients with `Rune.grad`, and updates parameters in a manual training loop.
